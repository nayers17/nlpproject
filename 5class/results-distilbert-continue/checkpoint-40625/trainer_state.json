{
  "best_metric": 0.9290845394134521,
  "best_model_checkpoint": "./5class/results-distilbert-continue/checkpoint-40625",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 40625,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.012307692307692308,
      "grad_norm": 6.310087203979492,
      "learning_rate": 1.8424615384615385e-06,
      "loss": 0.719,
      "step": 500
    },
    {
      "epoch": 0.024615384615384615,
      "grad_norm": 5.649205207824707,
      "learning_rate": 3.6886153846153847e-06,
      "loss": 0.7228,
      "step": 1000
    },
    {
      "epoch": 0.036923076923076927,
      "grad_norm": 4.884749412536621,
      "learning_rate": 5.534769230769232e-06,
      "loss": 0.706,
      "step": 1500
    },
    {
      "epoch": 0.04923076923076923,
      "grad_norm": 10.840557098388672,
      "learning_rate": 7.380923076923076e-06,
      "loss": 0.705,
      "step": 2000
    },
    {
      "epoch": 0.06153846153846154,
      "grad_norm": 8.234613418579102,
      "learning_rate": 9.223384615384617e-06,
      "loss": 0.7038,
      "step": 2500
    },
    {
      "epoch": 0.07384615384615385,
      "grad_norm": 4.984068870544434,
      "learning_rate": 1.1069538461538463e-05,
      "loss": 0.6919,
      "step": 3000
    },
    {
      "epoch": 0.08615384615384615,
      "grad_norm": 8.374109268188477,
      "learning_rate": 1.2912000000000001e-05,
      "loss": 0.6981,
      "step": 3500
    },
    {
      "epoch": 0.09846153846153846,
      "grad_norm": 5.820128440856934,
      "learning_rate": 1.4758153846153848e-05,
      "loss": 0.7005,
      "step": 4000
    },
    {
      "epoch": 0.11076923076923077,
      "grad_norm": 5.582093715667725,
      "learning_rate": 1.6604307692307694e-05,
      "loss": 0.7155,
      "step": 4500
    },
    {
      "epoch": 0.12307692307692308,
      "grad_norm": 8.266728401184082,
      "learning_rate": 1.845046153846154e-05,
      "loss": 0.6969,
      "step": 5000
    },
    {
      "epoch": 0.13538461538461538,
      "grad_norm": 9.009443283081055,
      "learning_rate": 2.0296615384615387e-05,
      "loss": 0.7009,
      "step": 5500
    },
    {
      "epoch": 0.1476923076923077,
      "grad_norm": 4.878206729888916,
      "learning_rate": 2.2142769230769233e-05,
      "loss": 0.7031,
      "step": 6000
    },
    {
      "epoch": 0.16,
      "grad_norm": 6.295515537261963,
      "learning_rate": 2.398523076923077e-05,
      "loss": 0.6915,
      "step": 6500
    },
    {
      "epoch": 0.1723076923076923,
      "grad_norm": 7.781266212463379,
      "learning_rate": 2.5831384615384616e-05,
      "loss": 0.7208,
      "step": 7000
    },
    {
      "epoch": 0.18461538461538463,
      "grad_norm": 12.026870727539062,
      "learning_rate": 2.7677538461538462e-05,
      "loss": 0.7056,
      "step": 7500
    },
    {
      "epoch": 0.19692307692307692,
      "grad_norm": 4.470708847045898,
      "learning_rate": 2.9523692307692306e-05,
      "loss": 0.7024,
      "step": 8000
    },
    {
      "epoch": 0.20923076923076922,
      "grad_norm": 9.537177085876465,
      "learning_rate": 2.9847794871794874e-05,
      "loss": 0.7211,
      "step": 8500
    },
    {
      "epoch": 0.22153846153846155,
      "grad_norm": 5.718046188354492,
      "learning_rate": 2.9642666666666667e-05,
      "loss": 0.71,
      "step": 9000
    },
    {
      "epoch": 0.23384615384615384,
      "grad_norm": 7.387417793273926,
      "learning_rate": 2.9437948717948717e-05,
      "loss": 0.7178,
      "step": 9500
    },
    {
      "epoch": 0.24615384615384617,
      "grad_norm": 8.994124412536621,
      "learning_rate": 2.9232820512820513e-05,
      "loss": 0.6984,
      "step": 10000
    },
    {
      "epoch": 0.25846153846153846,
      "grad_norm": 7.621398448944092,
      "learning_rate": 2.902769230769231e-05,
      "loss": 0.7058,
      "step": 10500
    },
    {
      "epoch": 0.27076923076923076,
      "grad_norm": 3.867316961288452,
      "learning_rate": 2.8822564102564105e-05,
      "loss": 0.7011,
      "step": 11000
    },
    {
      "epoch": 0.28307692307692306,
      "grad_norm": 6.710095405578613,
      "learning_rate": 2.8617846153846152e-05,
      "loss": 0.7029,
      "step": 11500
    },
    {
      "epoch": 0.2953846153846154,
      "grad_norm": 6.12627649307251,
      "learning_rate": 2.8412717948717948e-05,
      "loss": 0.6914,
      "step": 12000
    },
    {
      "epoch": 0.3076923076923077,
      "grad_norm": 8.81662368774414,
      "learning_rate": 2.8207589743589744e-05,
      "loss": 0.6917,
      "step": 12500
    },
    {
      "epoch": 0.32,
      "grad_norm": 8.243159294128418,
      "learning_rate": 2.800246153846154e-05,
      "loss": 0.6861,
      "step": 13000
    },
    {
      "epoch": 0.3323076923076923,
      "grad_norm": 5.7917561531066895,
      "learning_rate": 2.7797333333333332e-05,
      "loss": 0.6909,
      "step": 13500
    },
    {
      "epoch": 0.3446153846153846,
      "grad_norm": 7.747997760772705,
      "learning_rate": 2.759220512820513e-05,
      "loss": 0.6745,
      "step": 14000
    },
    {
      "epoch": 0.3569230769230769,
      "grad_norm": 8.723742485046387,
      "learning_rate": 2.7387076923076924e-05,
      "loss": 0.7042,
      "step": 14500
    },
    {
      "epoch": 0.36923076923076925,
      "grad_norm": 8.182809829711914,
      "learning_rate": 2.7182358974358975e-05,
      "loss": 0.6903,
      "step": 15000
    },
    {
      "epoch": 0.38153846153846155,
      "grad_norm": 6.136805057525635,
      "learning_rate": 2.6977230769230767e-05,
      "loss": 0.6718,
      "step": 15500
    },
    {
      "epoch": 0.39384615384615385,
      "grad_norm": 5.117434978485107,
      "learning_rate": 2.6772102564102563e-05,
      "loss": 0.6849,
      "step": 16000
    },
    {
      "epoch": 0.40615384615384614,
      "grad_norm": 9.215808868408203,
      "learning_rate": 2.656697435897436e-05,
      "loss": 0.6731,
      "step": 16500
    },
    {
      "epoch": 0.41846153846153844,
      "grad_norm": 5.580196380615234,
      "learning_rate": 2.6362256410256413e-05,
      "loss": 0.6747,
      "step": 17000
    },
    {
      "epoch": 0.4307692307692308,
      "grad_norm": 9.085679054260254,
      "learning_rate": 2.6157128205128206e-05,
      "loss": 0.6685,
      "step": 17500
    },
    {
      "epoch": 0.4430769230769231,
      "grad_norm": 19.09528350830078,
      "learning_rate": 2.5952e-05,
      "loss": 0.6767,
      "step": 18000
    },
    {
      "epoch": 0.4553846153846154,
      "grad_norm": 4.938198566436768,
      "learning_rate": 2.5746871794871794e-05,
      "loss": 0.6808,
      "step": 18500
    },
    {
      "epoch": 0.4676923076923077,
      "grad_norm": 18.789527893066406,
      "learning_rate": 2.5542153846153848e-05,
      "loss": 0.6685,
      "step": 19000
    },
    {
      "epoch": 0.48,
      "grad_norm": 6.935230255126953,
      "learning_rate": 2.533702564102564e-05,
      "loss": 0.6553,
      "step": 19500
    },
    {
      "epoch": 0.49230769230769234,
      "grad_norm": 11.5684175491333,
      "learning_rate": 2.5132307692307694e-05,
      "loss": 0.6646,
      "step": 20000
    },
    {
      "epoch": 0.5046153846153846,
      "grad_norm": 10.397186279296875,
      "learning_rate": 2.492717948717949e-05,
      "loss": 0.6665,
      "step": 20500
    },
    {
      "epoch": 0.5169230769230769,
      "grad_norm": 11.066668510437012,
      "learning_rate": 2.4722051282051283e-05,
      "loss": 0.6679,
      "step": 21000
    },
    {
      "epoch": 0.5292307692307693,
      "grad_norm": 13.37677001953125,
      "learning_rate": 2.4516923076923075e-05,
      "loss": 0.6654,
      "step": 21500
    },
    {
      "epoch": 0.5415384615384615,
      "grad_norm": 7.413442611694336,
      "learning_rate": 2.431179487179487e-05,
      "loss": 0.6576,
      "step": 22000
    },
    {
      "epoch": 0.5538461538461539,
      "grad_norm": 16.703857421875,
      "learning_rate": 2.4106666666666667e-05,
      "loss": 0.6713,
      "step": 22500
    },
    {
      "epoch": 0.5661538461538461,
      "grad_norm": 5.633275032043457,
      "learning_rate": 2.3901538461538463e-05,
      "loss": 0.6668,
      "step": 23000
    },
    {
      "epoch": 0.5784615384615385,
      "grad_norm": 11.334436416625977,
      "learning_rate": 2.3696410256410256e-05,
      "loss": 0.6681,
      "step": 23500
    },
    {
      "epoch": 0.5907692307692308,
      "grad_norm": 7.062133312225342,
      "learning_rate": 2.3491282051282052e-05,
      "loss": 0.649,
      "step": 24000
    },
    {
      "epoch": 0.6030769230769231,
      "grad_norm": 7.8506999015808105,
      "learning_rate": 2.3286153846153848e-05,
      "loss": 0.6647,
      "step": 24500
    },
    {
      "epoch": 0.6153846153846154,
      "grad_norm": 8.456216812133789,
      "learning_rate": 2.3081435897435898e-05,
      "loss": 0.6674,
      "step": 25000
    },
    {
      "epoch": 0.6276923076923077,
      "grad_norm": 9.68935775756836,
      "learning_rate": 2.287630769230769e-05,
      "loss": 0.669,
      "step": 25500
    },
    {
      "epoch": 0.64,
      "grad_norm": 4.575813293457031,
      "learning_rate": 2.2671589743589745e-05,
      "loss": 0.6725,
      "step": 26000
    },
    {
      "epoch": 0.6523076923076923,
      "grad_norm": 10.704124450683594,
      "learning_rate": 2.246646153846154e-05,
      "loss": 0.6518,
      "step": 26500
    },
    {
      "epoch": 0.6646153846153846,
      "grad_norm": 9.195213317871094,
      "learning_rate": 2.2261333333333333e-05,
      "loss": 0.6498,
      "step": 27000
    },
    {
      "epoch": 0.676923076923077,
      "grad_norm": 10.686983108520508,
      "learning_rate": 2.205620512820513e-05,
      "loss": 0.6513,
      "step": 27500
    },
    {
      "epoch": 0.6892307692307692,
      "grad_norm": 9.973111152648926,
      "learning_rate": 2.1851076923076925e-05,
      "loss": 0.6652,
      "step": 28000
    },
    {
      "epoch": 0.7015384615384616,
      "grad_norm": 4.558160305023193,
      "learning_rate": 2.1645948717948718e-05,
      "loss": 0.6599,
      "step": 28500
    },
    {
      "epoch": 0.7138461538461538,
      "grad_norm": 18.546443939208984,
      "learning_rate": 2.1440820512820514e-05,
      "loss": 0.6646,
      "step": 29000
    },
    {
      "epoch": 0.7261538461538461,
      "grad_norm": 5.782120704650879,
      "learning_rate": 2.1235692307692306e-05,
      "loss": 0.6608,
      "step": 29500
    },
    {
      "epoch": 0.7384615384615385,
      "grad_norm": 9.483230590820312,
      "learning_rate": 2.103097435897436e-05,
      "loss": 0.6487,
      "step": 30000
    },
    {
      "epoch": 0.7507692307692307,
      "grad_norm": 6.053442001342773,
      "learning_rate": 2.0825846153846156e-05,
      "loss": 0.6627,
      "step": 30500
    },
    {
      "epoch": 0.7630769230769231,
      "grad_norm": 5.8801703453063965,
      "learning_rate": 2.062071794871795e-05,
      "loss": 0.646,
      "step": 31000
    },
    {
      "epoch": 0.7753846153846153,
      "grad_norm": 7.433733940124512,
      "learning_rate": 2.0415589743589745e-05,
      "loss": 0.6458,
      "step": 31500
    },
    {
      "epoch": 0.7876923076923077,
      "grad_norm": 10.961539268493652,
      "learning_rate": 2.0210871794871795e-05,
      "loss": 0.6328,
      "step": 32000
    },
    {
      "epoch": 0.8,
      "grad_norm": 7.687763214111328,
      "learning_rate": 2.000574358974359e-05,
      "loss": 0.6468,
      "step": 32500
    },
    {
      "epoch": 0.8123076923076923,
      "grad_norm": 8.495156288146973,
      "learning_rate": 1.9800615384615384e-05,
      "loss": 0.6445,
      "step": 33000
    },
    {
      "epoch": 0.8246153846153846,
      "grad_norm": 9.275385856628418,
      "learning_rate": 1.959548717948718e-05,
      "loss": 0.647,
      "step": 33500
    },
    {
      "epoch": 0.8369230769230769,
      "grad_norm": 8.59520435333252,
      "learning_rate": 1.9390769230769233e-05,
      "loss": 0.6404,
      "step": 34000
    },
    {
      "epoch": 0.8492307692307692,
      "grad_norm": 12.309426307678223,
      "learning_rate": 1.9185641025641026e-05,
      "loss": 0.6485,
      "step": 34500
    },
    {
      "epoch": 0.8615384615384616,
      "grad_norm": 8.1600341796875,
      "learning_rate": 1.898051282051282e-05,
      "loss": 0.6401,
      "step": 35000
    },
    {
      "epoch": 0.8738461538461538,
      "grad_norm": 10.03754997253418,
      "learning_rate": 1.8775384615384614e-05,
      "loss": 0.64,
      "step": 35500
    },
    {
      "epoch": 0.8861538461538462,
      "grad_norm": 13.325922966003418,
      "learning_rate": 1.857025641025641e-05,
      "loss": 0.6501,
      "step": 36000
    },
    {
      "epoch": 0.8984615384615384,
      "grad_norm": 10.980252265930176,
      "learning_rate": 1.8365128205128206e-05,
      "loss": 0.6318,
      "step": 36500
    },
    {
      "epoch": 0.9107692307692308,
      "grad_norm": 8.22957992553711,
      "learning_rate": 1.8160410256410257e-05,
      "loss": 0.6386,
      "step": 37000
    },
    {
      "epoch": 0.9230769230769231,
      "grad_norm": 11.287602424621582,
      "learning_rate": 1.7955282051282053e-05,
      "loss": 0.6283,
      "step": 37500
    },
    {
      "epoch": 0.9353846153846154,
      "grad_norm": 10.099312782287598,
      "learning_rate": 1.775015384615385e-05,
      "loss": 0.6266,
      "step": 38000
    },
    {
      "epoch": 0.9476923076923077,
      "grad_norm": 8.384827613830566,
      "learning_rate": 1.754502564102564e-05,
      "loss": 0.6406,
      "step": 38500
    },
    {
      "epoch": 0.96,
      "grad_norm": 9.893150329589844,
      "learning_rate": 1.734030769230769e-05,
      "loss": 0.6366,
      "step": 39000
    },
    {
      "epoch": 0.9723076923076923,
      "grad_norm": 8.057788848876953,
      "learning_rate": 1.7135179487179488e-05,
      "loss": 0.6417,
      "step": 39500
    },
    {
      "epoch": 0.9846153846153847,
      "grad_norm": 12.507393836975098,
      "learning_rate": 1.6930051282051284e-05,
      "loss": 0.6345,
      "step": 40000
    },
    {
      "epoch": 0.9969230769230769,
      "grad_norm": 8.742094993591309,
      "learning_rate": 1.672492307692308e-05,
      "loss": 0.6267,
      "step": 40500
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.64072,
      "eval_f1": 0.6421518535351532,
      "eval_loss": 0.9290845394134521,
      "eval_precision": 0.6442754338087676,
      "eval_recall": 0.6407200000000001,
      "eval_runtime": 10.3798,
      "eval_samples_per_second": 4817.07,
      "eval_steps_per_second": 301.067,
      "step": 40625
    }
  ],
  "logging_steps": 500,
  "max_steps": 81250,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.1527103936e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
